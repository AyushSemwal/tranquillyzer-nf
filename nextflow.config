/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Shared parameters
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

includeConfig 'conf/params.config'

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Small helpers (avoid ConfigObject.trim() + null issues)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/
def _s(x) { x == null ? '' : x.toString() }
def _t(x) { _s(x).trim() }
def _binds() {
  (params.container_binds ?: [])
    .collect { "--bind ${it}" }
    .join(' ')
}

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Environment
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

env {
  // Only set if user provided params.cuda_lib_dir
  APPTAINERENV_LD_LIBRARY_PATH = _t(params.cuda_lib_dir)
    ? "${_t(params.cuda_lib_dir)}:${System.getenv('APPTAINERENV_LD_LIBRARY_PATH') ?: ''}"
    : null

  LD_LIBRARY_PATH = _t(params.cuda_lib_dir)
    ? "${_t(params.cuda_lib_dir)}:${System.getenv('LD_LIBRARY_PATH') ?: ''}"
    : null
}

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Global execution settings (driven by params)

    Set these in your params config (e.g. conf/tests/params_10x3p.config):
      params.executor         = 'slurm' | 'local'
      params.container_engine = 'docker' | 'singularity' | 'apptainer'
      params.enable_gpu       = true | false

    GPU behavior:
      - Users control all extra runtime flags via params.container_extra_opts (may be blank)
      - This config auto-prefixes the engine GPU flag when enable_gpu=true:
          docker      -> "--gpus all"
          singularity -> "--nv"
          apptainer   -> "--nv"

    Conventions:
      - label 'gpu' => gets GPU container options (only if enable_gpu)
      - label 'cpu' => never gets GPU flags
      - FEATURECOUNTS_MTX always uses subread container and never gets GPU options
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

// Choose executor from params (default local)
process.executor = (params.executor ?: 'local')

// If SLURM, apply defaults (override in params)
if (process.executor == 'slurm') {
  process.queue = params.slurm_queue ?: 'shen'
  process.time  = params.slurm_time  ?: '48h'
  process.cpus  = params.slurm_cpus  ?: 64
}

// Default container for most processes
process.container = params.container_trq

// Apply container engine selection from params
def _engine = (params.container_engine ?: '').toString().toLowerCase()

docker.enabled      = (_engine == 'docker')
singularity.enabled = (_engine == 'singularity')
apptainer.enabled   = (_engine == 'apptainer')

// Engine common settings
if (singularity.enabled) {
  singularity.autoMounts = true
  singularity.cacheDir   = params.image_dir
  singularity.runOptions = _binds()
}
if (apptainer.enabled) {
  apptainer.autoMounts = true
  apptainer.cacheDir   = params.image_dir
  apptainer.runOptions = _binds()
}

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Process-level container behavior (once; no duplicated profiles)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

process {

  // Always use subread container for featureCounts and never pass GPU flags to it
  withName: 'TRANQUILLYZER_PIPELINE:FEATURECOUNTS_MTX' {
    container        = params.container_subread
    containerOptions = ''
    clusterOptions   = ''
  }

  // CPU-labeled processes: never add GPU flags
  withLabel: 'cpu' {
    containerOptions = _t(params.container_extra_opts)
  }

  // GPU-labeled processes: add engine GPU flag + user extra opts, only if enabled
  withLabel: 'gpu' {
    def extra = _t(params.container_extra_opts)
    def gpuEnabled = (params.enable_gpu == true)

    def gpuPrefix = ''
    if (gpuEnabled) {
      if (docker.enabled) {
        gpuPrefix = '--gpus all'
      } else if (singularity.enabled || apptainer.enabled) {
        gpuPrefix = '--nv'
      }
    }

    containerOptions = gpuEnabled
      ? "${gpuPrefix} ${extra}".trim()
      : extra

    // Optional: SLURM GPU resource request flags (cluster-specific)
    clusterOptions = (process.executor == 'slurm' && gpuEnabled && _t(params.slurm_gpu_opts))
      ? _t(params.slurm_gpu_opts)
      : ''
  }
}

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Minimal profiles (optional convenience only)
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

profiles {
  standard { }
}

/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Output reports
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
*/

trace {
  enabled   = true
  file      = "${params.outdir}/pipeline_info/execution_trace.tsv"
  sep       = '\t'
  fields    = 'tag,task_id,process,status,exit,submit,start,complete,realtime,%cpu,cpus,peak_rss,peak_vmem'
  overwrite = true
}

report {
  enabled   = true
  file      = "${params.outdir}/pipeline_info/execution_report.html"
  overwrite = true
}

timeline {
  enabled   = true
  file      = "${params.outdir}/pipeline_info/execution_timeline.html"
  overwrite = true
}

dag {
  enabled   = true
  file      = "${params.outdir}/pipeline_info/pipeline_dag.svg"
  overwrite = true
}